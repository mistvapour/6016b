#!/usr/bin/env python3
"""
ç»Ÿä¸€å¤šæ ¼å¼è‡ªåŠ¨åŒ–å¯¼å…¥ç³»ç»Ÿ
æ”¯æŒPDFã€XMLã€JSONã€CSVã€DOCXç­‰å¤šç§æ ¼å¼çš„è‡ªåŠ¨è¯†åˆ«ã€è½¬æ¢å’Œå¯¼å…¥
"""
import os
import mimetypes
from pathlib import Path
from typing import Dict, List, Any, Optional, Union
from abc import ABC, abstractmethod
import logging
from datetime import datetime
import json
import yaml

# æ ¼å¼æ£€æµ‹
import magic
import fitz  # PyMuPDF
import xml.etree.ElementTree as ET
import pandas as pd

# ç°æœ‰æ¨¡å—
from pdf_adapter.pdf_processor import PDFProcessor
from import_yaml import YAMLImporter

logger = logging.getLogger(__name__)

class FormatAdapter(ABC):
    """æ ¼å¼é€‚é…å™¨æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    def can_handle(self, file_path: str, mime_type: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦èƒ½å¤„ç†æ­¤æ ¼å¼"""
        pass
    
    @abstractmethod
    def detect_standard(self, file_path: str) -> Dict[str, Any]:
        """æ£€æµ‹æ–‡ä»¶çš„æ ‡å‡†ç±»å‹å’Œç‰ˆæœ¬"""
        pass
    
    @abstractmethod
    def process(self, file_path: str, **kwargs) -> Dict[str, Any]:
        """å¤„ç†æ–‡ä»¶å¹¶è¿”å›æ ‡å‡†åŒ–ç»“æœ"""
        pass
    
    @abstractmethod
    def get_supported_formats(self) -> List[str]:
        """è¿”å›æ”¯æŒçš„æ ¼å¼åˆ—è¡¨"""
        pass

class PDFAdapter(FormatAdapter):
    """PDFæ ¼å¼é€‚é…å™¨"""
    
    def __init__(self):
        self.processor = PDFProcessor()
    
    def can_handle(self, file_path: str, mime_type: str) -> bool:
        return mime_type == 'application/pdf' or file_path.lower().endswith('.pdf')
    
    def detect_standard(self, file_path: str) -> Dict[str, Any]:
        """æ£€æµ‹PDFæ ‡å‡†ç±»å‹"""
        try:
            doc = fitz.open(file_path)
            text_sample = ""
            
            # æå–å‰å‡ é¡µçš„æ–‡æœ¬è¿›è¡Œåˆ†æ
            for page_num in range(min(5, len(doc))):
                text_sample += doc[page_num].get_text()
            
            text_lower = text_sample.lower()
            
            # æ ‡å‡†æ£€æµ‹è§„åˆ™
            if 'mil-std-6016' in text_lower or 'link 16' in text_lower:
                return {
                    "standard": "MIL-STD-6016",
                    "type": "Link16",
                    "adapter": "pdf_adapter",
                    "confidence": 0.95,
                    "pages": len(doc),
                    "processing_method": "6016_specialized"
                }
            elif 'mqtt' in text_lower and ('control packet' in text_lower or 'publish' in text_lower):
                return {
                    "standard": "MQTT",
                    "type": "Protocol",
                    "adapter": "mqtt_adapter", 
                    "confidence": 0.90,
                    "pages": len(doc),
                    "processing_method": "mqtt_specialized"
                }
            elif any(kw in text_lower for kw in ['j2.0', 'j2.1', 'j2.2', 'j2.3', 'j2.4']):
                return {
                    "standard": "MIL-STD-6016",
                    "type": "J-Series",
                    "adapter": "pdf_adapter",
                    "confidence": 0.85,
                    "pages": len(doc),
                    "processing_method": "j_series_focused"
                }
            else:
                return {
                    "standard": "Generic",
                    "type": "PDF",
                    "adapter": "generic_pdf",
                    "confidence": 0.60,
                    "pages": len(doc),
                    "processing_method": "generic_table_extraction"
                }
                
        except Exception as e:
            logger.error(f"PDFæ ‡å‡†æ£€æµ‹å¤±è´¥: {e}")
            return {
                "standard": "Unknown",
                "type": "PDF",
                "adapter": "generic_pdf",
                "confidence": 0.30,
                "error": str(e),
                "processing_method": "fallback"
            }
    
    def process(self, file_path: str, **kwargs) -> Dict[str, Any]:
        """å¤„ç†PDFæ–‡ä»¶"""
        try:
            standard_info = self.detect_standard(file_path)
            
            if standard_info["standard"] == "MIL-STD-6016":
                # ä½¿ç”¨ç°æœ‰çš„6016å¤„ç†å™¨
                result = self.processor.process_pdf(
                    file_path,
                    standard="MIL-STD-6016",
                    **kwargs
                )
                result["detected_standard"] = standard_info
                return result
                
            elif standard_info["standard"] == "MQTT":
                # ä½¿ç”¨MQTTå¤„ç†å™¨
                from mqtt_adapter.extract_tables import read_tables, pick_best_tables
                from mqtt_adapter.parse_sections import detect_sections
                from mqtt_adapter.build_sim import build_sim
                from mqtt_adapter.export_yaml import export_yaml
                
                # MQTTå¤„ç†æµç¨‹
                pages = kwargs.get('pages', '1-100')
                page_list = self._parse_pages(pages)
                
                doc = fitz.open(file_path)
                page_texts = {p: doc[p-1].get_text() for p in page_list if 1 <= p <= len(doc)}
                
                per_page_tables = read_tables(file_path, page_list)
                best_tables = pick_best_tables(per_page_tables)
                sections = detect_sections(page_texts)
                sim = build_sim(sections, best_tables)
                
                # å¯¼å‡ºYAML
                output_dir = kwargs.get('output_dir', '/tmp/mqtt_processing')
                os.makedirs(output_dir, exist_ok=True)
                yaml_path = os.path.join(output_dir, f"{Path(file_path).stem}.yaml")
                export_yaml(sim, yaml_path)
                
                return {
                    "success": True,
                    "standard": "MQTT",
                    "yaml_path": yaml_path,
                    "messages": [m["label"] for m in sim["spec_messages"]],
                    "detected_standard": standard_info
                }
            
            else:
                # é€šç”¨PDFå¤„ç†
                return self._process_generic_pdf(file_path, **kwargs)
                
        except Exception as e:
            logger.error(f"PDFå¤„ç†å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "file_path": file_path
            }
    
    def _parse_pages(self, pages_str: str) -> List[int]:
        """è§£æé¡µé¢èŒƒå›´å­—ç¬¦ä¸²"""
        page_list = []
        for part in pages_str.split(","):
            if "-" in part:
                a, b = map(int, part.split("-"))
                page_list.extend(range(a, b + 1))
            else:
                page_list.append(int(part))
        return page_list
    
    def _process_generic_pdf(self, file_path: str, **kwargs) -> Dict[str, Any]:
        """é€šç”¨PDFå¤„ç†"""
        # å®ç°é€šç”¨PDFè¡¨æ ¼æå–å’Œæ•°æ®å¤„ç†
        return {
            "success": True,
            "standard": "Generic",
            "message": "é€šç”¨PDFå¤„ç†å®Œæˆ",
            "file_path": file_path
        }
    
    def get_supported_formats(self) -> List[str]:
        return ['.pdf', 'application/pdf']

class XMLAdapter(FormatAdapter):
    """XMLæ ¼å¼é€‚é…å™¨"""
    
    def can_handle(self, file_path: str, mime_type: str) -> bool:
        return mime_type in ['application/xml', 'text/xml'] or file_path.lower().endswith('.xml')
    
    def detect_standard(self, file_path: str) -> Dict[str, Any]:
        """æ£€æµ‹XMLæ ‡å‡†ç±»å‹"""
        try:
            tree = ET.parse(file_path)
            root = tree.getroot()
            
            # MAVLinkæ£€æµ‹
            if root.tag == 'mavlink' or 'mavlink' in str(root.attrib).lower():
                return {
                    "standard": "MAVLink",
                    "type": "Protocol",
                    "adapter": "mavlink_xml",
                    "confidence": 0.95,
                    "root_element": root.tag,
                    "processing_method": "mavlink_specialized"
                }
            
            # æ£€æµ‹å…¶ä»–æ ‡å‡†
            elif root.tag in ['protocol', 'specification', 'standard']:
                return {
                    "standard": "Generic Protocol",
                    "type": "XML",
                    "adapter": "generic_xml",
                    "confidence": 0.70,
                    "root_element": root.tag,
                    "processing_method": "generic_xml"
                }
            
            else:
                return {
                    "standard": "Generic",
                    "type": "XML",
                    "adapter": "generic_xml",
                    "confidence": 0.50,
                    "root_element": root.tag,
                    "processing_method": "generic_xml"
                }
                
        except Exception as e:
            logger.error(f"XMLæ ‡å‡†æ£€æµ‹å¤±è´¥: {e}")
            return {
                "standard": "Unknown",
                "type": "XML",
                "adapter": "generic_xml",
                "confidence": 0.30,
                "error": str(e),
                "processing_method": "fallback"
            }
    
    def process(self, file_path: str, **kwargs) -> Dict[str, Any]:
        """å¤„ç†XMLæ–‡ä»¶"""
        try:
            standard_info = self.detect_standard(file_path)
            
            if standard_info["standard"] == "MAVLink":
                # ä½¿ç”¨ç°æœ‰çš„MAVLinkè½¬æ¢å™¨
                from xml_to_pdf_converter import MAVLinkXMLConverter
                
                converter = MAVLinkXMLConverter(file_path)
                result = converter.run_conversion()
                
                if result["success"]:
                    yaml_path = result["files_generated"]["yaml"]
                    return {
                        "success": True,
                        "standard": "MAVLink",
                        "yaml_path": yaml_path,
                        "statistics": result["statistics"],
                        "detected_standard": standard_info
                    }
                else:
                    return {
                        "success": False,
                        "error": result.get("error"),
                        "detected_standard": standard_info
                    }
            
            else:
                # é€šç”¨XMLå¤„ç†
                return self._process_generic_xml(file_path, **kwargs)
                
        except Exception as e:
            logger.error(f"XMLå¤„ç†å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "file_path": file_path
            }
    
    def _process_generic_xml(self, file_path: str, **kwargs) -> Dict[str, Any]:
        """é€šç”¨XMLå¤„ç†"""
        try:
            tree = ET.parse(file_path)
            root = tree.getroot()
            
            # ç®€å•çš„XMLåˆ°å­—å…¸è½¬æ¢
            def xml_to_dict(element):
                result = {}
                for child in element:
                    if len(child) == 0:
                        result[child.tag] = child.text
                    else:
                        result[child.tag] = xml_to_dict(child)
                return result
            
            data = xml_to_dict(root)
            
            # ç”ŸæˆYAMLæ–‡ä»¶
            output_dir = kwargs.get('output_dir', 'xml_output')
            os.makedirs(output_dir, exist_ok=True)
            yaml_path = os.path.join(output_dir, f"{Path(file_path).stem}.yaml")
            
            with open(yaml_path, 'w', encoding='utf-8') as f:
                yaml.safe_dump(data, f, sort_keys=False, allow_unicode=True)
            
            return {
                "success": True,
                "standard": "Generic XML",
                "yaml_path": yaml_path,
                "elements_count": len(data),
                "message": "é€šç”¨XMLå¤„ç†å®Œæˆ"
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def get_supported_formats(self) -> List[str]:
        return ['.xml', 'application/xml', 'text/xml']

class JSONAdapter(FormatAdapter):
    """JSONæ ¼å¼é€‚é…å™¨"""
    
    def can_handle(self, file_path: str, mime_type: str) -> bool:
        return mime_type == 'application/json' or file_path.lower().endswith('.json')
    
    def detect_standard(self, file_path: str) -> Dict[str, Any]:
        """æ£€æµ‹JSONæ ‡å‡†ç±»å‹"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æ£€æµ‹ä¸åŒçš„JSONæ ¼å¼
            if isinstance(data, dict):
                if 'spec_messages' in data and 'standard' in data:
                    return {
                        "standard": data.get('standard', 'Unknown'),
                        "type": "SIM",
                        "adapter": "sim_json",
                        "confidence": 0.90,
                        "processing_method": "direct_import"
                    }
                elif 'messages' in data or 'enums' in data:
                    return {
                        "standard": "Protocol Definition",
                        "type": "JSON",
                        "adapter": "protocol_json",
                        "confidence": 0.80,
                        "processing_method": "protocol_conversion"
                    }
            
            return {
                "standard": "Generic",
                "type": "JSON",
                "adapter": "generic_json",
                "confidence": 0.60,
                "processing_method": "generic_conversion"
            }
            
        except Exception as e:
            logger.error(f"JSONæ ‡å‡†æ£€æµ‹å¤±è´¥: {e}")
            return {
                "standard": "Unknown",
                "type": "JSON",
                "adapter": "generic_json",
                "confidence": 0.30,
                "error": str(e),
                "processing_method": "fallback"
            }
    
    def process(self, file_path: str, **kwargs) -> Dict[str, Any]:
        """å¤„ç†JSONæ–‡ä»¶"""
        try:
            standard_info = self.detect_standard(file_path)
            
            with open(file_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            if standard_info["type"] == "SIM":
                # ç›´æ¥è½¬æ¢ä¸ºYAMLå¹¶å¯¼å…¥
                output_dir = kwargs.get('output_dir', 'json_output')
                os.makedirs(output_dir, exist_ok=True)
                yaml_path = os.path.join(output_dir, f"{Path(file_path).stem}.yaml")
                
                with open(yaml_path, 'w', encoding='utf-8') as f:
                    yaml.safe_dump(data, f, sort_keys=False, allow_unicode=True)
                
                return {
                    "success": True,
                    "standard": standard_info["standard"],
                    "yaml_path": yaml_path,
                    "message": "JSON SIMæ•°æ®è½¬æ¢å®Œæˆ",
                    "detected_standard": standard_info
                }
            
            else:
                # é€šç”¨JSONå¤„ç†
                return self._process_generic_json(data, file_path, **kwargs)
                
        except Exception as e:
            logger.error(f"JSONå¤„ç†å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "file_path": file_path
            }
    
    def _process_generic_json(self, data: Any, file_path: str, **kwargs) -> Dict[str, Any]:
        """é€šç”¨JSONå¤„ç†"""
        try:
            # ç”Ÿæˆæ ‡å‡†åŒ–çš„YAML
            output_dir = kwargs.get('output_dir', 'json_output')
            os.makedirs(output_dir, exist_ok=True)
            yaml_path = os.path.join(output_dir, f"{Path(file_path).stem}.yaml")
            
            # åŒ…è£…æˆæ ‡å‡†æ ¼å¼
            standardized_data = {
                "standard": "Generic JSON",
                "edition": "1.0",
                "source_file": file_path,
                "data": data,
                "metadata": {
                    "conversion_time": datetime.now().isoformat(),
                    "converter": "json_adapter"
                }
            }
            
            with open(yaml_path, 'w', encoding='utf-8') as f:
                yaml.safe_dump(standardized_data, f, sort_keys=False, allow_unicode=True)
            
            return {
                "success": True,
                "standard": "Generic JSON",
                "yaml_path": yaml_path,
                "message": "é€šç”¨JSONå¤„ç†å®Œæˆ"
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def get_supported_formats(self) -> List[str]:
        return ['.json', 'application/json']

class CSVAdapter(FormatAdapter):
    """CSVæ ¼å¼é€‚é…å™¨"""
    
    def can_handle(self, file_path: str, mime_type: str) -> bool:
        return mime_type == 'text/csv' or file_path.lower().endswith('.csv')
    
    def detect_standard(self, file_path: str) -> Dict[str, Any]:
        """æ£€æµ‹CSVæ ‡å‡†ç±»å‹"""
        try:
            # è¯»å–å‰å‡ è¡Œæ¥æ£€æµ‹ç»“æ„
            df = pd.read_csv(file_path, nrows=5)
            
            # æ£€æµ‹åˆ—åæ¥åˆ¤æ–­ç±»å‹
            columns = [col.lower() for col in df.columns]
            
            if any(col in columns for col in ['message', 'field', 'bits', 'name']):
                return {
                    "standard": "Protocol Definition",
                    "type": "CSV",
                    "adapter": "protocol_csv",
                    "confidence": 0.80,
                    "columns": len(df.columns),
                    "processing_method": "protocol_csv"
                }
            
            elif any(col in columns for col in ['enum', 'value', 'code', 'label']):
                return {
                    "standard": "Enum Definition",
                    "type": "CSV",
                    "adapter": "enum_csv",
                    "confidence": 0.75,
                    "columns": len(df.columns),
                    "processing_method": "enum_csv"
                }
            
            else:
                return {
                    "standard": "Generic",
                    "type": "CSV",
                    "adapter": "generic_csv",
                    "confidence": 0.60,
                    "columns": len(df.columns),
                    "processing_method": "generic_csv"
                }
                
        except Exception as e:
            logger.error(f"CSVæ ‡å‡†æ£€æµ‹å¤±è´¥: {e}")
            return {
                "standard": "Unknown",
                "type": "CSV",
                "adapter": "generic_csv",
                "confidence": 0.30,
                "error": str(e),
                "processing_method": "fallback"
            }
    
    def process(self, file_path: str, **kwargs) -> Dict[str, Any]:
        """å¤„ç†CSVæ–‡ä»¶"""
        try:
            standard_info = self.detect_standard(file_path)
            df = pd.read_csv(file_path)
            
            # æ ¹æ®æ£€æµ‹ç»“æœé€‰æ‹©å¤„ç†æ–¹æ³•
            if standard_info["standard"] == "Protocol Definition":
                return self._process_protocol_csv(df, file_path, **kwargs)
            elif standard_info["standard"] == "Enum Definition":
                return self._process_enum_csv(df, file_path, **kwargs)
            else:
                return self._process_generic_csv(df, file_path, **kwargs)
                
        except Exception as e:
            logger.error(f"CSVå¤„ç†å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "file_path": file_path
            }
    
    def _process_protocol_csv(self, df: pd.DataFrame, file_path: str, **kwargs) -> Dict[str, Any]:
        """å¤„ç†åè®®å®šä¹‰CSV"""
        try:
            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            messages = []
            
            # å‡è®¾CSVæœ‰ message, field, bits, description ç­‰åˆ—
            for _, row in df.iterrows():
                # æ ¹æ®å®é™…CSVç»“æ„è°ƒæ•´
                message_data = {
                    "name": row.get('field', row.get('name', '')),
                    "description": row.get('description', ''),
                    "bits": row.get('bits', ''),
                }
                messages.append(message_data)
            
            # ç”ŸæˆYAML
            output_dir = kwargs.get('output_dir', 'csv_output')
            os.makedirs(output_dir, exist_ok=True)
            yaml_path = os.path.join(output_dir, f"{Path(file_path).stem}.yaml")
            
            yaml_data = {
                "standard": "CSV Protocol",
                "edition": "1.0",
                "source_file": file_path,
                "spec_messages": [{"label": "CSV_DATA", "fields": messages}],
                "metadata": {
                    "conversion_time": datetime.now().isoformat(),
                    "converter": "csv_adapter",
                    "rows_processed": len(df)
                }
            }
            
            with open(yaml_path, 'w', encoding='utf-8') as f:
                yaml.safe_dump(yaml_data, f, sort_keys=False, allow_unicode=True)
            
            return {
                "success": True,
                "standard": "CSV Protocol",
                "yaml_path": yaml_path,
                "rows_processed": len(df),
                "message": "åè®®CSVå¤„ç†å®Œæˆ"
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def _process_enum_csv(self, df: pd.DataFrame, file_path: str, **kwargs) -> Dict[str, Any]:
        """å¤„ç†æšä¸¾å®šä¹‰CSV"""
        # ç±»ä¼¼åè®®å¤„ç†ï¼Œä½†é’ˆå¯¹æšä¸¾ç»“æ„
        return self._process_generic_csv(df, file_path, **kwargs)
    
    def _process_generic_csv(self, df: pd.DataFrame, file_path: str, **kwargs) -> Dict[str, Any]:
        """é€šç”¨CSVå¤„ç†"""
        try:
            # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
            data = df.to_dict('records')
            
            # ç”ŸæˆYAML
            output_dir = kwargs.get('output_dir', 'csv_output')
            os.makedirs(output_dir, exist_ok=True)
            yaml_path = os.path.join(output_dir, f"{Path(file_path).stem}.yaml")
            
            yaml_data = {
                "standard": "Generic CSV",
                "edition": "1.0",
                "source_file": file_path,
                "data": data,
                "metadata": {
                    "conversion_time": datetime.now().isoformat(),
                    "converter": "csv_adapter",
                    "rows": len(df),
                    "columns": list(df.columns)
                }
            }
            
            with open(yaml_path, 'w', encoding='utf-8') as f:
                yaml.safe_dump(yaml_data, f, sort_keys=False, allow_unicode=True)
            
            return {
                "success": True,
                "standard": "Generic CSV",
                "yaml_path": yaml_path,
                "rows_processed": len(df),
                "columns": list(df.columns),
                "message": "é€šç”¨CSVå¤„ç†å®Œæˆ"
            }
            
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def get_supported_formats(self) -> List[str]:
        return ['.csv', 'text/csv']

class UniversalImportSystem:
    """ç»Ÿä¸€å¯¼å…¥ç³»ç»Ÿä¸»ç±»"""
    
    def __init__(self):
        self.adapters = [
            PDFAdapter(),
            XMLAdapter(),
            JSONAdapter(),
            CSVAdapter(),
        ]
        self.yaml_importer = YAMLImporter()
        
    def detect_file_format(self, file_path: str) -> Dict[str, Any]:
        """æ£€æµ‹æ–‡ä»¶æ ¼å¼å’ŒMIMEç±»å‹"""
        try:
            # ä½¿ç”¨æ–‡ä»¶æ‰©å±•åå’Œmagicæ£€æµ‹
            mime_type = mimetypes.guess_type(file_path)[0]
            
            # å¦‚æœmimetypesæ£€æµ‹ä¸åˆ°ï¼Œä½¿ç”¨python-magic
            if not mime_type:
                try:
                    mime_type = magic.from_file(file_path, mime=True)
                except:
                    # å›é€€åˆ°æ‰©å±•åæ£€æµ‹
                    ext = Path(file_path).suffix.lower()
                    mime_map = {
                        '.pdf': 'application/pdf',
                        '.xml': 'application/xml',
                        '.json': 'application/json',
                        '.csv': 'text/csv',
                        '.yaml': 'application/x-yaml',
                        '.yml': 'application/x-yaml'
                    }
                    mime_type = mime_map.get(ext, 'application/octet-stream')
            
            return {
                "file_path": file_path,
                "mime_type": mime_type,
                "extension": Path(file_path).suffix.lower(),
                "size": os.path.getsize(file_path),
                "detected_at": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"æ–‡ä»¶æ ¼å¼æ£€æµ‹å¤±è´¥: {e}")
            return {
                "file_path": file_path,
                "mime_type": "unknown",
                "extension": Path(file_path).suffix.lower(),
                "error": str(e)
            }
    
    def find_adapter(self, file_path: str, mime_type: str) -> Optional[FormatAdapter]:
        """æŸ¥æ‰¾é€‚åˆçš„æ ¼å¼é€‚é…å™¨"""
        for adapter in self.adapters:
            if adapter.can_handle(file_path, mime_type):
                return adapter
        return None
    
    def process_file(self, file_path: str, **kwargs) -> Dict[str, Any]:
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        try:
            logger.info(f"å¼€å§‹å¤„ç†æ–‡ä»¶: {file_path}")
            
            # æ£€æµ‹æ–‡ä»¶æ ¼å¼
            format_info = self.detect_file_format(file_path)
            
            # æŸ¥æ‰¾é€‚é…å™¨
            adapter = self.find_adapter(file_path, format_info["mime_type"])
            
            if not adapter:
                return {
                    "success": False,
                    "error": f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {format_info['mime_type']}",
                    "format_info": format_info,
                    "supported_formats": self.get_supported_formats()
                }
            
            # æ£€æµ‹æ ‡å‡†ç±»å‹
            standard_info = adapter.detect_standard(file_path)
            
            # å¤„ç†æ–‡ä»¶
            process_result = adapter.process(file_path, **kwargs)
            
            # ç»„åˆç»“æœ
            result = {
                "success": process_result.get("success", True),
                "file_path": file_path,
                "format_info": format_info,
                "standard_info": standard_info,
                "adapter_used": adapter.__class__.__name__,
                "process_result": process_result,
                "processed_at": datetime.now().isoformat()
            }
            
            return result
            
        except Exception as e:
            logger.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "file_path": file_path
            }
    
    def process_files(self, file_paths: List[str], **kwargs) -> Dict[str, Any]:
        """æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶"""
        results = []
        summary = {
            "total_files": len(file_paths),
            "successful": 0,
            "failed": 0,
            "by_format": {},
            "by_standard": {}
        }
        
        for file_path in file_paths:
            try:
                result = self.process_file(file_path, **kwargs)
                results.append(result)
                
                if result["success"]:
                    summary["successful"] += 1
                    
                    # ç»Ÿè®¡æ ¼å¼
                    format_type = result.get("format_info", {}).get("mime_type", "unknown")
                    summary["by_format"][format_type] = summary["by_format"].get(format_type, 0) + 1
                    
                    # ç»Ÿè®¡æ ‡å‡†
                    standard = result.get("standard_info", {}).get("standard", "unknown")
                    summary["by_standard"][standard] = summary["by_standard"].get(standard, 0) + 1
                    
                else:
                    summary["failed"] += 1
                    
            except Exception as e:
                logger.error(f"å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")
                results.append({
                    "success": False,
                    "file_path": file_path,
                    "error": str(e)
                })
                summary["failed"] += 1
        
        return {
            "success": summary["failed"] == 0,
            "summary": summary,
            "results": results,
            "processed_at": datetime.now().isoformat()
        }
    
    def import_to_database(self, yaml_paths: List[str], dry_run: bool = True) -> Dict[str, Any]:
        """å°†å¤„ç†ç»“æœå¯¼å…¥æ•°æ®åº“"""
        try:
            import_results = []
            
            for yaml_path in yaml_paths:
                if os.path.exists(yaml_path):
                    result = self.yaml_importer.import_yaml_file(yaml_path, dry_run)
                    import_results.append({
                        "yaml_path": yaml_path,
                        "result": result
                    })
                else:
                    import_results.append({
                        "yaml_path": yaml_path,
                        "result": {
                            "success": False,
                            "error": f"YAMLæ–‡ä»¶ä¸å­˜åœ¨: {yaml_path}"
                        }
                    })
            
            # æ±‡æ€»ç»“æœ
            successful_imports = sum(1 for r in import_results if r["result"].get("success"))
            
            return {
                "success": successful_imports > 0,
                "total_yamls": len(yaml_paths),
                "successful_imports": successful_imports,
                "failed_imports": len(yaml_paths) - successful_imports,
                "dry_run": dry_run,
                "results": import_results
            }
            
        except Exception as e:
            logger.error(f"æ•°æ®åº“å¯¼å…¥å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def complete_pipeline(self, file_paths: List[str], import_to_db: bool = False, dry_run: bool = True, **kwargs) -> Dict[str, Any]:
        """å®Œæ•´çš„å¤„ç†æµæ°´çº¿ï¼šæ–‡ä»¶å¤„ç† -> YAMLç”Ÿæˆ -> æ•°æ®åº“å¯¼å…¥"""
        try:
            # ç¬¬ä¸€æ­¥ï¼šå¤„ç†æ–‡ä»¶
            process_result = self.process_files(file_paths, **kwargs)
            
            if not process_result["success"]:
                return {
                    "success": False,
                    "stage": "file_processing",
                    "error": "æ–‡ä»¶å¤„ç†é˜¶æ®µå¤±è´¥",
                    "details": process_result
                }
            
            # æ”¶é›†ç”Ÿæˆçš„YAMLæ–‡ä»¶
            yaml_paths = []
            for result in process_result["results"]:
                if result["success"] and "yaml_path" in result.get("process_result", {}):
                    yaml_paths.append(result["process_result"]["yaml_path"])
            
            result = {
                "success": True,
                "stage": "complete",
                "file_processing": process_result,
                "yaml_files_generated": yaml_paths
            }
            
            # ç¬¬äºŒæ­¥ï¼šæ•°æ®åº“å¯¼å…¥ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if import_to_db and yaml_paths:
                import_result = self.import_to_database(yaml_paths, dry_run)
                result["database_import"] = import_result
                
                if not import_result["success"]:
                    result["success"] = False
                    result["stage"] = "database_import"
                    result["error"] = "æ•°æ®åº“å¯¼å…¥é˜¶æ®µå¤±è´¥"
            
            return result
            
        except Exception as e:
            logger.error(f"å®Œæ•´æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {e}")
            return {
                "success": False,
                "stage": "pipeline_error",
                "error": str(e)
            }
    
    def get_supported_formats(self) -> Dict[str, List[str]]:
        """è·å–æ‰€æœ‰æ”¯æŒçš„æ ¼å¼"""
        supported = {}
        for adapter in self.adapters:
            adapter_name = adapter.__class__.__name__
            supported[adapter_name] = adapter.get_supported_formats()
        return supported
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        return {
            "adapters_loaded": len(self.adapters),
            "supported_formats": self.get_supported_formats(),
            "system_ready": True,
            "timestamp": datetime.now().isoformat()
        }

def main():
    """æµ‹è¯•å’Œæ¼”ç¤º"""
    system = UniversalImportSystem()
    
    print("ğŸ¯ ç»Ÿä¸€å¤šæ ¼å¼å¯¼å…¥ç³»ç»Ÿ")
    print("=" * 50)
    
    # æ˜¾ç¤ºæ”¯æŒçš„æ ¼å¼
    print("ğŸ“‹ æ”¯æŒçš„æ ¼å¼:")
    for adapter, formats in system.get_supported_formats().items():
        print(f"   {adapter}: {', '.join(formats)}")
    
    print("\\nâœ… ç³»ç»Ÿå°±ç»ªï¼Œå¯ä»¥å¤„ç†å¤šç§æ ¼å¼çš„æ–‡ä»¶!")

if __name__ == "__main__":
    main()
